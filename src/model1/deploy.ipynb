{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy and Test your Model in 7 Easy Steps\n",
    "## Step 1: Get Access to your Registered Model in your Workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SDK version: 1.7.0\n"
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mlserviceworkspace\nmlserviceworkspace\nwestus2\n601f4351-33bb-4d76-96ca-886940409b3d\n"
    }
   ],
   "source": [
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sklearn_regression_model.pkl\nliveliness_detection1\nautomlux\ntf-dnn-mnist\nautoml-local-regression-wipro\namlstudio-experiment-created-o\nbattery_failure_predictor\nface_liveliness\nAutoMLef8e3168e9\nmask_rcnn_horovod\nentity-extraction-from-text\ntoystfod\nkeras_animals\nkeras_pets_1\nmnist\ndemo-model\ntextDNN-20News\nazure-service-classifier\nAutoML6129f25231\ngerman-credit\nAdultCensus.mml\nbest_model_local\ntf-dnn-mnist-phonepe\namlstudio-automobile-price-dat\nliveliness_detection\nAutoMLca4f003cf9\nliveliness_model\nAutoML3ad4cb6ac9\nAutoMLf11867afa0\nfraud_detection\nentityextraction\nfruitspredictor\nkeras_\nkeras_pets_2\ntfod\nkeras_pets\nazure-service-classifier-rl\ninception\nkeras-mlp-mnist\ngerman-credit-scb\n"
    }
   ],
   "source": [
    "# The below code lists all the models in your ML workspace\n",
    "for model in ws.models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Model(workspace=Workspace.create(name='mlserviceworkspace', subscription_id='601f4351-33bb-4d76-96ca-886940409b3d', resource_group='mlserviceworkspace'), name=german-credit-model, id=german-credit-model:2, version=2, tags={}, properties={})"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "model = Model(ws,\"german-credit-model\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Create an Inference Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "myenv = Environment(\"GermanCreditInference\")\n",
    "\n",
    "conda_dep = CondaDependencies()\n",
    "conda_dep.add_conda_package(\"scikit-learn\")\n",
    "conda_dep.add_conda_package(\"joblib\")\n",
    "conda_dep.add_pip_package(\"azureml-defaults\")\n",
    "conda_dep.add_pip_package(\"azureml-core\")\n",
    "conda_dep.add_pip_package(\"inference-schema\")\n",
    "\n",
    "# Adds dependencies to PythonSection of myenv\n",
    "myenv.python.conda_dependencies=conda_dep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Write the Scoring Script\n",
    "\n",
    "1.Init method loads the model in a global object\n",
    "\n",
    "2.Run method scores the incoming data against the model and returns results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "import json\nimport os\nimport numpy as np\nimport pandas as pd\nimport joblib\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n\ndef init():\n    global model\n    \n    # Update to your model's filename\n    model_filename = \"model.pkl\"\n\n    # AZUREML_MODEL_DIR is injected by AML\n    model_dir = os.getenv('AZUREML_MODEL_DIR')\n\n    print(\"Model dir:\", model_dir)\n    print(\"Model filename:\", model_filename)\n    \n    model_path = os.path.join(model_dir, model_filename)\n\n    # Replace this line with your model loading code\n    model = joblib.load(model_path)\n\n# Define some sample data for automatic generation of swagger interface\ninput_sample = [{\n    \"Age\": 20,\n    \"Sex\": \"male\",\n    \"Job\": 0,\n    \"Housing\": \"own\",\n    \"Saving accounts\": \"little\",\n    \"Checking account\": \"little\",\n    \"Credit amount\": 100,\n    \"Duration\": 48,\n    \"Purpose\": \"radio/TV\"\n  }]\noutput_sample = [[0.7, 0.3]]\n\n# This will automatically unmarshall the data parameter in the HTTP request\n@input_schema('data', StandardPythonParameterType(input_sample))\n@output_schema(StandardPythonParameterType(output_sample))\ndef run(data):\n    try:\n        input_df = pd.DataFrame(data)\n        proba = model.predict_proba(input_df)\n        \n        result = {\"predict_proba\": proba.tolist()}\n        return result\n    except Exception as e:\n        error = str(e)\n        return error\n"
    }
   ],
   "source": [
    "with open('./score.py', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create an Inference Configuration\n",
    "\n",
    "An Inference Configuration is your Scoring script + Inference environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\",\n",
    "                                   environment=myenv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Provision the AKS Compute Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "# Use the default configuration (can also provide parameters to customize)\n",
    "prov_config = AksCompute.provisioning_configuration()\n",
    "aks_config = AksWebservice.deploy_configuration()\n",
    "\n",
    "aks_name = 'akscompute' \n",
    "# Create the cluster\n",
    "aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                  name = aks_name, \n",
    "                                  provisioning_configuration = prov_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Creating......................................................................................\nSucceededProvisioning operation finished, operation \"Succeeded\"\nSucceeded\nNone\nCPU times: user 566 ms, sys: 64.8 ms, total: 630 ms\nWall time: 7min 24s\n"
    }
   ],
   "source": [
    "%%time\n",
    "aks_target.wait_for_completion(show_output = True)\n",
    "print(aks_target.provisioning_state)\n",
    "print(aks_target.provisioning_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AksCompute(workspace=Workspace.create(name='mlserviceworkspace', subscription_id='601f4351-33bb-4d76-96ca-886940409b3d', resource_group='mlserviceworkspace'), name=akscompute, id=/subscriptions/601f4351-33bb-4d76-96ca-886940409b3d/resourceGroups/mlserviceworkspace/providers/Microsoft.MachineLearningServices/workspaces/mlserviceworkspace/computes/akscompute, type=AKS, provisioning_state=Succeeded, location=westus2, tags=None)"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "aks_name = 'akscompute' \n",
    "aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
    "aks_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Deploy the Model on AKS Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Running.......................\nSucceeded\nAKS service creation operation finished, operation \"Succeeded\"\nHealthy\nCPU times: user 397 ms, sys: 57.9 ms, total: 455 ms\nWall time: 2min 22s\n"
    }
   ],
   "source": [
    "%%time\n",
    "aks_service_name ='mlops-german-credit'\n",
    "aks_config = AksWebservice.deploy_configuration()\n",
    "aks_service = Model.deploy(workspace=ws,\n",
    "                           name=aks_service_name,\n",
    "                           models=[model],\n",
    "                           inference_config=inference_config,\n",
    "                           deployment_config=aks_config,\n",
    "                           deployment_target=aks_target,\n",
    "                           overwrite=True)\n",
    "\n",
    "aks_service.wait_for_deployment(show_output = True)\n",
    "print(aks_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_service = AksWebservice(ws, name = aks_service_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'http://20.191.115.183:80/api/v1/service/mlops-german-credit/score'"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "aks_service.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('ysYsWIRE4NXdOwTAVNwcKvP0JbQAWp4Y', 'WLgrXbPCmE9IxrR0Fh8t7YZwsA4dBxE6')"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "aks_service.get_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Test your Model in AKS\n",
    "\n",
    "Use the aks-endpoint.http(tests folder) file or Postman or  REST call to test the scoring endpoint"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3-azureml",
   "display_name": "Python 3.6 - AzureML"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}